{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to see what was needed to run the planet generator with the saved training file.\n",
    "#### A version of this code now sits on heroku to power the bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import re\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = load_model('./astroph_no_dropout_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temp(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len, temp):\n",
    "    output_text = seed_text\n",
    "    \n",
    "    seed_text = start_title + seed_text\n",
    "    \n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = token_list[-max_sequence_len:]\n",
    "        token_list = np.reshape(token_list, (1, max_sequence_len))\n",
    "        \n",
    "        probs = model.predict(token_list, verbose=0)[0]\n",
    "        y_class = sample_with_temp(probs, temperature = temp)\n",
    "        \n",
    "        if y_class == 0:\n",
    "            output_word = ''\n",
    "        else:\n",
    "            output_word = tokenizer.index_word[y_class]\n",
    "            \n",
    "        if output_word == \"|\":\n",
    "            break\n",
    "            \n",
    "        output_text += output_word + ' '\n",
    "        seed_text += output_word + ' '\n",
    " \n",
    "                    \n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./papertitles_text.txt\"\n",
    "\n",
    "with open(filename, encoding='utf-8-sig') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "start = 0 \n",
    "end = len(text) \n",
    "text = text[start:end]\n",
    "\n",
    "tokenizer = Tokenizer(char_level = False, filters = '')\n",
    "tokenizer.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine to switch generated title from lower-case back to title-like punctuation \n",
    "# Basically a bunch of clunky string manipulation.\n",
    "def capitalise(title):\n",
    "    \n",
    "    # words that shouldn't be capitalised unless their the first word in the title\n",
    "    unimportant=[\"a\", \"an\", \"the\", \"am\" ,\"is\", \"are\", \"and\", \"of\", \"in\" , \"on\", \"with\", \"from\", \"to\", \"as\", \"by\"]\n",
    "    # Acroynms that should be all caps\n",
    "    capitalize = [\"ska\", \"ngc\", \"grb\", \"ii\"]\n",
    "\n",
    "    resp=\"\"\n",
    "    v = title.split()\n",
    "    for idx, x in enumerate(v):\n",
    "        if x not in unimportant:\n",
    "            if x in capitalize:\n",
    "                resp += (\" \" + x.upper())\n",
    "            else: \n",
    "                resp += (\" \" + ''.join(x.capitalize()))\n",
    "        else:\n",
    "            if idx == 0: # first word\n",
    "                resp += (\" \" + ''.join(x.capitalize()))\n",
    "            else:\n",
    "                resp += (\" \" + x)\n",
    "\n",
    "    return resp\n",
    "\n",
    "print(capitalise(\"an example of a title. SKA and the galaxy's stars.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text =  \" \"   \n",
    "gen_words = 35\n",
    "temp = 0.8\n",
    "max_seq_length = 10\n",
    "start_title = '| ' * max_seq_length\n",
    "\n",
    "text = generate_text(seed_text, gen_words, model, max_seq_length, temp)\n",
    "print(\"Original text: \", text)\n",
    "    \n",
    "# remove duplicate words, e.g. \"the the\"\n",
    "text = ' '.join(c[0] for c in itertools.groupby(text.split()))\n",
    "\n",
    "#check if in training set (sometimes title is just from the training set.)\n",
    "# (In the bot, the title is re-generated if it's a duplicate.)\n",
    "training = open(\"./astrobotph_twitter/papertitles_list.txt\", \"r\")\n",
    "training_titles = []\n",
    "for line in training:\n",
    "    training_titles.append(line.strip())\n",
    "    \n",
    "if text in training_titles:\n",
    "    print(\"match: \", text)\n",
    "else:\n",
    "    text = capitalise(text)\n",
    "    \n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes to experiment with string recognition and reply in the tweet to the bot\n",
    "buffer = \"@astrobotph “planet“\"\n",
    "buffer = \"\\\"planet\\\"\"\n",
    "quotes = re.split('\\\" |\\\"|\\” |\\”|\\“ |\\“|\\” |\\”|\\“ |\\“|\\*|\\n', buffer)[1:2][0].strip().lower()+\" \"\n",
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = \"\\\"\" + quotes + \"\\\"\"\n",
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_text = \"Congratulations! Your paper \" + \"\\\"\"+text.strip()+ \"\\\"\" + \" has been accepted to the Journal of AstRobotomy.\"\n",
    "tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
